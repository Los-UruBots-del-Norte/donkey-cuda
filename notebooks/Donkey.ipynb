{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLdjQ-JQFYVG"
   },
   "source": [
    "## Check GPU and Tensorflow version\n",
    "If \"Found GPU at: / device: GPU: 0\" is displayed, the GPU is ready to use.*italicized text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "F6WhKuZxJ5IK",
    "outputId": "a35418f5-51df-4f3c-a632-37207605ca60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/sctse999/keras-vis\n",
      "  Cloning https://github.com/sctse999/keras-vis to /tmp/pip-req-build-ma4bvhul\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/sctse999/keras-vis /tmp/pip-req-build-ma4bvhul\n",
      "  Resolved https://github.com/sctse999/keras-vis to commit 93e1e803dc0779e25f95b6c1e871d499414e5404\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in ./lib/python3.11/site-packages (from keras-vis==0.5.0) (1.16.0)\n",
      "Collecting scikit-image (from keras-vis==0.5.0)\n",
      "  Downloading scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting matplotlib (from keras-vis==0.5.0)\n",
      "  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: h5py in ./lib/python3.11/site-packages (from keras-vis==0.5.0) (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./lib/python3.11/site-packages (from h5py->keras-vis==0.5.0) (1.26.4)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.11/site-packages (from matplotlib->keras-vis==0.5.0) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->keras-vis==0.5.0)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./lib/python3.11/site-packages (from matplotlib->keras-vis==0.5.0) (2.9.0.post0)\n",
      "Collecting scipy>=1.9 (from scikit-image->keras-vis==0.5.0)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.8 (from scikit-image->keras-vis==0.5.0)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting imageio>=2.33 (from scikit-image->keras-vis==0.5.0)\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->keras-vis==0.5.0)\n",
      "  Downloading tifffile-2024.5.10-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->keras-vis==0.5.0)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.5.10-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: keras-vis\n",
      "  Building wheel for keras-vis (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-vis: filename=keras_vis-0.5.0-py2.py3-none-any.whl size=30955 sha256=72a49b34c559d77598dfdff79cbd3ac1c1dc3a336a0bbc9a3c419f285de1e551\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5lxsyowp/wheels/ca/d3/f0/41afc8b1b487ac063a1924b5bc302f74187ebb48e6b74f3b17\n",
      "Successfully built keras-vis\n",
      "Installing collected packages: tifffile, scipy, pyparsing, pillow, networkx, lazy-loader, kiwisolver, fonttools, cycler, contourpy, matplotlib, imageio, scikit-image, keras-vis\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 imageio-2.34.1 keras-vis-0.5.0 kiwisolver-1.4.5 lazy-loader-0.4 matplotlib-3.9.0 networkx-3.3 pillow-10.3.0 pyparsing-3.1.2 scikit-image-0.23.2 scipy-1.13.0 tifffile-2024.5.10\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tqdm<5.0,>=4.11.2 (from moviepy)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.8.1 in ./lib/python3.11/site-packages (from moviepy) (2.31.0)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./lib/python3.11/site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in ./lib/python3.11/site-packages (from moviepy) (2.34.1)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in ./lib/python3.11/site-packages (from imageio<3.0,>=2.5->moviepy) (10.3.0)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.11/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110721 sha256=65932670f4b1dd670d5fe6963caf72b533d776d261b72a7cb4e3ce6f7e81c296\n",
      "  Stored in directory: /home/adminutec/.cache/pip/wheels/83/b1/d9/119ef7c144b44d591ec0a9a140465133c23ea95d2a161184ba\n",
      "Successfully built moviepy\n",
      "Installing collected packages: tqdm, imageio_ffmpeg, decorator, proglog, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10 tqdm-4.66.4\n",
      "Requirement already satisfied: ipykernel in ./lib/python3.11/site-packages (6.29.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./lib/python3.11/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./lib/python3.11/site-packages (from ipykernel) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./lib/python3.11/site-packages (from ipykernel) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./lib/python3.11/site-packages (from ipykernel) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./lib/python3.11/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./lib/python3.11/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./lib/python3.11/site-packages (from ipykernel) (24.0)\n",
      "Requirement already satisfied: psutil in ./lib/python3.11/site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in ./lib/python3.11/site-packages (from ipykernel) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in ./lib/python3.11/site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras-vis\n",
    "!pip install git+https://github.com/sctse999/keras-vis\n",
    "\n",
    "!pip install moviepy\n",
    "\n",
    "!pip3 install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqwkW1S46O93",
    "outputId": "17325069-868d-49ca-892d-ee979221e879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.16.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/adminutec/jupyter-venv/lib/python3.11/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n",
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Eb8y6kG-JgpW",
    "outputId": "af522da8-a309-46b7-8d9c-af8e6d9607db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: /content/: No such file or directory\n",
      "Cloning into 'donkeycar'...\n",
      "remote: Enumerating objects: 16402, done.\u001b[K\n",
      "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
      "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
      "remote: Total 16402 (delta 42), reused 63 (delta 35), pack-reused 16301\u001b[K\n",
      "Receiving objects: 100% (16402/16402), 90.17 MiB | 2.27 MiB/s, done.\n",
      "Resolving deltas: 100% (10862/10862), done.\n",
      "[Errno 2] No such file or directory: '/content/donkeycar'\n",
      "/home/adminutec/jupyter-venv\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adminutec/jupyter-venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/adminutec/jupyter-venv\n",
      "\u001b[31mERROR: file:///home/adminutec/jupyter-venv does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/autorope/donkeycar\n",
    "!git checkout main\n",
    "!pip3 install -e .[pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLaAn5wXJmXB",
    "outputId": "eaa67311-128c-41e9-bab8-a937ca830097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________             ______                   _________              \n",
      "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
      "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
      "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
      "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
      "                                 /____/                              \n",
      "\n",
      "using donkey v5.2.dev1 ...\n",
      "Creating car folder: /content/mycar\n",
      "making dir  /content/mycar\n",
      "Creating data & model folders.\n",
      "making dir  /content/mycar/models\n",
      "making dir  /content/mycar/data\n",
      "making dir  /content/mycar/logs\n",
      "Copying car application template: complete\n",
      "Copying car config defaults. Adjust these before starting your car.\n",
      "Copying train script. Adjust these before starting your car.\n",
      "Copying calibrate script. Adjust these before starting your car.\n",
      "Copying my car config overrides\n",
      "Donkey setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Create car\n",
    "!donkey createcar --path /content/mycar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qve7ipmYf0IH"
   },
   "outputs": [],
   "source": [
    "# Change config in the following array of key-value pairs\n",
    "config=[(\"EARLY_STOP_PATIENCE\",\"8\"),(\"CREATE_TF_LITE\",\"True\"),(\"AUGMENTATIONS\",\"[]\"),(\"BATCH_SIZE\",\"64\"),\n",
    "        (\"MAX_EPOCHS\",\"60\"),(\"OPTIMIZER\",\"sgd\"),\"\"]\n",
    "\n",
    "def update_config(file_path, key_value_pairs):\n",
    "    # Read the existing content from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Create a dictionary from the key-value pairs for quick lookup\n",
    "    updates = {key: f\"{key}={value}\\n\" for key, value in key_value_pairs}\n",
    "\n",
    "    # Replace or uncomment lines containing the keys\n",
    "    new_keys = updates.copy()\n",
    "    commented_values = {}\n",
    "    for i, line in enumerate(lines):\n",
    "        original_line = line.strip()\n",
    "        is_commented = original_line.startswith('#')\n",
    "        uncommented_line = original_line.lstrip('#').strip()\n",
    "        key_part = uncommented_line.split('=')[0].strip()\n",
    "\n",
    "        if key_part in updates:\n",
    "            # Capture the value from commented lines for possible replacement\n",
    "            if is_commented:\n",
    "                commented_values[key_part] = uncommented_line.split('=')[1].strip()\n",
    "            # Replace or uncomment the line based on its status\n",
    "            new_value = commented_values.get(key_part, updates[key_part].split('=')[1]).strip()\n",
    "\n",
    "            lines[i] = f\"{key_part}={new_value}\\n\"\n",
    "            del new_keys[key_part]\n",
    "    # Append any new keys that were not found in the file\n",
    "    lines.extend(new_keys.values())\n",
    "\n",
    "    # Write the modified content back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Example usage\n",
    "update_config('/mycar/myconfig.py', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SoNuZKdCidt",
    "outputId": "8cf1fe52-8d75-4a5d-cce7-8ca84be31b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU mem:16G, batch_size:256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*16\n",
    "print(f'GPU mem:{int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)}G, batch_size:{batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIvUrZ4k0w9N",
    "outputId": "f45035d7-8986-4c23-8b6d-3b0154a1387e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mycar\n",
      "mkdir: cannot create directory ‘/content/mycar/data’: File exists\n",
      "File downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Download zips with data, follow that zip structure\n",
    "# /\n",
    "# - images/\n",
    "# - catalog_0.catalog\n",
    "# - catalog_0.catalog_manifest\n",
    "# ...\n",
    "\n",
    "file_names = []\n",
    "file_paths = []\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL of the file you want to download\n",
    "urls = ['https://download1655.mediafire.com/91456qb1mcsg_qO9IJqm6Iw3DQ6cpGn47aGX3Tb5AulOMOYZqKvknnxurZtX7-4AA9hwBG7rnhyliolLnW4KePmLDvAguWXQDRYLP1lMfVML2SWKWeHtlk6Cm8226E1xSgUviOpX7VnnsoERFGUflmYHbrdawCTPd0OrRTxiMQ0/vqdv1vs3gb8vhk4/data-640x480-16-35.zip']\n",
    "counter = 0\n",
    "# Send a GET request to the URL\n",
    "for url in urls:\n",
    "  response = requests.get(url)\n",
    "  # Ensure the request was successful\n",
    "  if response.status_code == 200:\n",
    "    file_name = f\"data-{counter}.zip\"\n",
    "    counter += 1\n",
    "    file_names.append(file_name)\n",
    "    with open(f'/{file_name}', 'wb') as f:\n",
    "        # Write the content of the response to the file\n",
    "        file_paths.append(f'/{file_name}')\n",
    "        f.write(response.content)\n",
    "        print(\"File downloaded successfully!\")\n",
    "  else:\n",
    "    print(\"Failed to retrieve the file. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RweMGL9JKnlz",
    "outputId": "0357635f-f3d9-4ac2-f430-b267c9528b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unpacking: content/data-0.zip\n",
      "Extracted all files in content/data-0.zip to content/mycar/data/data-0\n"
     ]
    }
   ],
   "source": [
    "# Unzip downloaded files\n",
    "\n",
    "file_names=[\"data-0.zip\"]\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unpack_zip(file_path, extract_to):\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted all files in {file_path} to {extract_to}\")\n",
    "def unpack_file(file_path, extract_to):\n",
    "    _, file_ext = os.path.splitext(file_path)\n",
    "\n",
    "    if file_ext in ['.zip']:\n",
    "        unpack_zip(file_path, extract_to)\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_ext}\")\n",
    "def safe_unpack_file(file_path, extract_to):\n",
    "    try:\n",
    "        print(f\"unpacking: \" + file_path)\n",
    "        unpack_file(file_path, extract_to)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "target_directory = \"mycar/data/\"\n",
    "src_directory = \"./\"\n",
    "for filename in file_names:\n",
    "    if os.path.isfile(os.path.join(target_directory, filename)):  # Check if it is a file\n",
    "        # Extract the file name without the extension\n",
    "        file_base = os.path.splitext(filename)[0]\n",
    "        # Create a path for the new subfolder\n",
    "        new_folder_path = os.path.join(target_directory, file_base)\n",
    "for file_name in file_names:\n",
    "  safe_unpack_file(src_directory + file_name, (target_directory + file_name)[:-len('.zip')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"mycar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jerrmrSfaD_f",
    "outputId": "0fc7c6c3-8ec7-4e2e-f5a8-798bb85b9870"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:donkeycar.config:loading config file: ./config.py\n",
      "INFO:donkeycar.config:loading personal config over-rides from ./myconfig.py\n",
      "2024-05-18 13:40:53.232338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-18 13:40:53.232362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-18 13:40:53.233232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-18 13:40:53.237830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-18 13:40:53.837126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:donkeycar.pipeline.database:No model database found at /home/adminutec/jupyter-venv/content/mycar/models/database.json\n",
      "INFO:donkeycar.utils:get_model_by_type: model type is: linear\n",
      "2024-05-18 13:40:55.140116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.169431: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.169618: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.170133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.170277: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.170419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.234854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.235057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.235205: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-18 13:40:55.235304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9366 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "INFO:donkeycar.parts.keras:Created KerasLinear with interpreter: KerasInterpreter\n",
      "INFO:donkeycar.parts.datastore_v2:Found datastore at /home/adminutec/jupyter-venv/content/mycar/data/data-0\n",
      "INFO:donkeycar.parts.datastore_v2:Using last catalog /home/adminutec/jupyter-venv/content/mycar/data/data-0/catalog_2.catalog\n",
      "INFO:donkeycar.pipeline.types:Loading tubs from paths ['data/data-0']\n",
      "INFO:donkeycar.pipeline.training:Records # Training 1701\n",
      "INFO:donkeycar.pipeline.training:Records # Validation 426\n",
      "INFO:donkeycar.parts.tub_v2:Closing tub data/data-0\n",
      "INFO:donkeycar.parts.datastore_v2:Closing manifest /home/adminutec/jupyter-venv/content/mycar/data/data-0\n",
      "INFO:donkeycar.pipeline.training:Train with image caching: True\n",
      "INFO:donkeycar.parts.keras:////////// Starting training //////////\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________             ______                   _________              \n",
      "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
      "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
      "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
      "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
      "                                 /____/                              \n",
      "\n",
      "using donkey v5.2.dev1 ...\n",
      "Model: \"linear\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_in (InputLayer)         [(None, 240, 320, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 118, 158, 24)         1824      ['img_in[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 118, 158, 24)         0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 57, 77, 32)           19232     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 57, 77, 32)           0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 27, 37, 64)           51264     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 27, 37, 64)           0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 25, 35, 64)           36928     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 25, 35, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 23, 33, 64)           36928     ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 23, 33, 64)           0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " flattened (Flatten)         (None, 48576)                0         ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 100)                  4857700   ['flattened[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 100)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 50)                   5050      ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 50)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " n_outputs0 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " n_outputs1 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5009028 (19.11 MB)\n",
      "Trainable params: 5009028 (19.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Creating ImageTransformations []\n",
      "Creating ImageTransformations []\n",
      "Creating ImageTransformations []\n",
      "Creating ImageTransformations []\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 13:40:56.360618: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inlinear/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-05-18 13:40:56.689001: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-18 13:40:56.769902: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.989193: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.989328: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.989489: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.990425: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.991289: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.992152: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.993686: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:56.994312: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.024362: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.025044: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.025183: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.025231: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.025609: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.026658: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.027454: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.031020: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.031265: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.054593: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.547473: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.571068: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.650266: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.651399: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.651687: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.652414: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.653119: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.653751: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.654060: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.654581: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.684093: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.685906: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.686472: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.686495: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.686923: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.687707: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.687741: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.690636: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-05-18 13:40:57.839840: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f4254e3f0a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-18 13:40:57.839858: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-05-18 13:40:57.843839: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-18 13:40:57.874065: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-05-18 13:40:57.897830: F external/local_xla/xla/service/gpu/nvptx_compiler.cc:591] ptxas returned an error during compilation of ptx to sass: 'INTERNAL: ptxas exited with non-zero error code 65280, output: ptxas /tmp/tempfile-UTECLNX-6023-c8096442-97175-618bd21f54eac, line 5; fatal   : Unsupported .version 7.1; current version is '6.4'\n",
      "ptxas fatal   : Ptx assembly aborted due to errors\n",
      "'  If the error message indicates that a file could not be written, please verify that sufficient filesystem space is provided.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['donkey', 'train', '--tub', 'data/data-0', '--model', 'models/mypilot.h5'], returncode=-6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"mypilot\"\n",
    "import subprocess\n",
    "import os\n",
    "subprocess.run([\"donkey\", \"train\", \"--tub\", \"data/data-0\", \"--model\", \"models/mypilot.h5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
